# 評価者用マニュアル

## 概要
このマニュアルは、AIテスト受験者の作業を評価する評価者AIのためのガイドラインです。

## 🚨 重要：時刻記録の絶対ルール 🚨
**全てのAI（受験者・評価者）は以下を厳守すること：**
- **時刻は必ず`date`コマンドで取得する**
- 手動での時刻記載は禁止
- 例: `date '+%Y%m%d %H:%M:%S'` または `date '+%Y年%m月%d日 %H:%M'`
- work_history.log、評価レポート、その他全ての記録に適用

```bash
# 正しい例
CURRENT_TIME=$(date '+%Y%m%d %H:%M:%S')
echo "[作業者名] $CURRENT_TIME 作業内容" >> work_history.log

# 間違った例（禁止）
echo "[作業者名] 20250813 09:00:00 作業内容" >> work_history.log
```

## 評価者の役割と責任

### 1. 基本情報の明記
- **評価者名**: 必ず自分の名前を明記（例：test1-AI（評価者））
- **作業記録**: 評価作業もwork_history.logに記録する
  - 形式: `[評価者名] YYYYMMDD HH:MM:SS 作業内容`

### 2. 評価対象フォルダ
評価を依頼されたフォルダ（例：test2, test2-v2）の以下を確認：
- 全ファイル・フォルダの存在確認
- work_history.logの記録確認
- reflection.txtの内容確認（文字化けも報告）

## 評価手順

### Step 1: 作業内容の確認
```bash
# フォルダ構造の確認
ls -la [対象フォルダ]

# work_history.logの確認
cat [対象フォルダ]/work_history.log

# reflection.txtの確認
cat [対象フォルダ]/reflection.txt
```

### Step 2: 検証スクリプトの実行（存在する場合）
```bash
cd [対象フォルダ]
python3 verification.py  # または類似の検証スクリプト
```
**重要**: 実行結果を必ず記録する

### Step 3: 計算・処理結果の検証
- 手動で計算を再確認
- ファイル内容と期待値の照合
- 形式要件（小数点桁数等）の確認
- **重要**: エラーや修正があった場合は必ず記録

### Step 4: feedbackフォルダの作成
```bash
mkdir [対象フォルダ]/feedback
```

### Step 5: 評価レポートの作成
`[対象フォルダ]/feedback/evaluation_report.md`を作成

### Step 6: next_prompt.txtの作成
次のAI用の課題を作成（難易度を段階的に上げる）

## 評価基準（100点満点）

### 標準配点
1. **フォルダ・ファイル作成要件**: 25点
   - 指定された数と名前の確認
   - ファイル配置の正確性

2. **処理結果の正確性**: 35点
   - 計算結果の正誤
   - 形式要件の遵守（小数点等）

3. **追加要件の実装**: 20点
   - CSV、JSON等の作成
   - 検証スクリプトの作成

4. **ルール遵守**: 20点
   - work_history.logへの記録: 10点
   - reflection.txtへの記載: 10点

## 評価レポートテンプレート

```markdown
# [フォルダ名] 作業評価レポート

## 評価者情報
- **評価者**: [評価者名]
- **評価日時**: [日時]
- **作業者**: [作業者名]

## 採点結果
- フォルダ・ファイル作成: __/25点
- 処理結果の正確性: __/35点
- 追加要件: __/20点
- ルール遵守: __/20点

## 総合評価: __/100点

## 詳細な批評
### 優れている点
- 

### 改善が必要な点
- 

## 総評
```

## next_prompt.txt作成ガイドライン

### 難易度の段階的向上
**避けるべき難易度向上**:
- 指示の分散・不明確化
- 同じ内容の冗長な繰り返し

**推奨する難易度向上**:
- 作業項目数の増加（3→5→7→10）
- 計算の複雑化（四則演算→累乗→対数）
- ファイル形式の多様化（txt→CSV→JSON→YAML）
- 条件分岐の追加
- エラーハンドリングの要求

### 難易度レベルの目安
- **Level 1（10点）**: 3-4フォルダ、基本計算、txtファイル
- **Level 2（15点）**: 5フォルダ、複雑計算、CSV追加
- **Level 3（20点）**: 7フォルダ、JSON形式、検証スクリプト
- **Level 4（25点）**: 10フォルダ、条件分岐、エラー処理
- **Level 5（30点）**: 階層構造、API模擬、非同期処理

## reflection.txt記載ガイドライン

### 必須記載項目（作業プロセスの振り返り）

**1. エラー・問題の記録**
```
【発生したエラー】
- エラーなし → 「エラーなし」と明記
- エラーあり → 以下を記載
  - どのコマンドでエラーが発生したか
  - エラーメッセージの内容
  - 何回エラーが発生したか
  - どう解決したか

例:
- mkdir実行時: Permission deniedエラー → sudoで解決
- Python実行時: ImportError → mathライブラリのインポート追加で解決（3回試行）
- 計算ミス: analysis_4で初回181.264と計算 → 再計算で181.365に修正
```

**2. 指示の明確さ**
```
【指示について】
- 分かりやすかった点
- 分かりづらかった/曖昧だった点
- 解釈に迷った部分

例:
- 「小数点第3位まで」が四捨五入か切り捨てか不明 → 四捨五入と解釈
- renameの意味が不明確だった
```

**3. 作業の困難さ**
```
【困難だった作業】
- 技術的に難しかった計算や処理
- 時間がかかった部分
- 複数回やり直した作業

例:
- 階乗計算で大きな数値のオーバーフロー対策
- JSONの階層構造作成に手間取った
```

**4. 工夫した点（従来通り）**
```
【工夫した点】
- 効率化のための工夫
- エラー防止のための対策
- 品質向上のための取り組み
```

**5. 改善案（プロセス改善＋システム改善）**
```
【改善案】
- プロセス改善: 作業手順の改善提案
- システム改善: ツールや自動化の提案
- 指示改善: より明確な指示の書き方提案
```

### reflection.txt記載例
```
[テストAI5] reflection.txt

【発生したエラー】
1. Python実行時: NameError 'math' → import math追加で解決（1回）
2. mkdir analysis_9実行時: 既に存在 → rm -rfで削除後再作成（1回）
3. 計算ミス: analysis_3で260.909を260.91と記載 → 修正（1回）

【指示について】
- 明確だった点: 計算式と小数点桁数の指定
- 不明確だった点: 「rename」の意味（フォルダ名を指定の名前にすること？）
- 解釈に迷った点: verification.txtの「別の方法」がどの程度別であるべきか

【困難だった作業】
1. analysis_8の階乗計算: 大きな数値の扱い
2. 統計値の標準偏差計算: 手動計算が複雑
3. JSONの入れ子構造: 正しい形式の確認に時間

【工夫した点】
1. 計算を段階的に実行して中間値を確認
2. 検証スクリプトを早めに作成して動作確認
3. CSVとJSONの両方で結果を保存

【改善案】
1. プロセス改善: 計算用の補助スクリプトを最初に作成
2. システム改善: バリデーション機能を組み込んだテンプレート提供
3. 指示改善: 用語の定義を明確に（例：「rename」→「以下の名前でフォルダを作成」）
```

## 注意事項

### 評価作業の記録
**必ず記録すべき作業**:
- 検証スクリプトの実行
- 計算結果の手動確認
- feedbackフォルダの作成
- 評価レポートの作成

### 文字化け問題への対処
- 文字化けを発見したら必ず報告
- 可能な範囲で内容を推測
- 減点は最小限に（システム側の問題の可能性）

### 公平性の確保
- 同じ課題でも個体差があることを理解
- 部分点を適切に配分
- 良い点も必ず記載

## サブエージェント活用による自動テスト実施

### 仕組みの概要
評価者はサブエージェントを呼び出してテスト受験者の作業を実施させることができます。

### 実施手順
1. **test[番号]フォルダとprompt.txt作成**
2. **サブエージェント呼び出し**
   ```
   Taskツール使用
   - subagent_type: softengineer-expert
   - prompt: 課題内容と作業者名指定
   ```
3. **作業完了後、自動評価**
4. **feedbackフォルダに評価レポート作成**
5. **evaluator/work_history.logに記録**

### フォルダ構成
```
claude-manual-test-100/
├── tests/
│   └── test[番号]/     # 受験者の作業
│       ├── work_history.log
│       └── feedback/
├── evaluator/          # 評価者専用
│   ├── work_history.log
│   └── logs/
```

## 関連ドキュメント

1. **evaluation_guidelines.md** - 詳細な判断基準
   - 配点調整の具体例
   - エラー対処法
   - 文字化け判断基準

2. **evaluation_template.md** - 評価レポートテンプレート
   - コピーして使用

3. **evaluation_checklist.md** - 作業チェックリスト
   - ステップバイステップ確認

4. **next_prompt_examples.md** - 課題作成例集
   - 難易度別の具体例
   - 避けるべきパターン

## 評価者への指示例

```
以下のフォルダの作業を評価してください。
evaluator-manualのREADME.mdとevaluation_guidelines.mdに従って評価を実施してください。
※windows pathです。
C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100
→ tests/[対象フォルダ名]を評価
```