# AIテスト評価ガイド

## 評価指示を受けたら

あなたが受け取った指示（例：`test1`）を以下のように解釈してください：

- **test1** = 評価対象のテスト番号

### 評価手順

1. **評価対象AIを自動選択**
   ```bash
   ls C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\executions\
   ls C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\evaluations\
   ```
   - executionsフォルダ内の実施済みAIを確認
   - evaluationsフォルダ内の既存評価を確認し、**各AIが何人に評価されているかカウント**
   - **最も評価人数が少ないAIを選択**（例：AI_001が3人、AI_002が1人なら、AI_002を選択）
   - 同じ評価人数の場合は番号が若いAIを優先
   - **重要：既に評価済みのAIでも、追加の評価者として評価を実施してください**
   - あなたが何人目の評価者かを確認（例：既に3人評価済みなら、あなたは4人目）

2. **評価者番号を自動採番**
   ```bash
   ls C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\evaluations\
   ```
   - evaluationsフォルダ内の既存フォルダを確認
   - 最大番号+1で自分の評価者番号を決定（例：最大がEVAL_005なら、EVAL_006を採番）

3. **評価者フォルダ作成**
   ```
   C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\evaluations\EVAL_[番号]\
   ```

4. **評価対象AIの実施確認**
   ```bash
   ls C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\executions\[自動選択したAI番号]\
   ```
   **フォルダ内にファイルが存在するか確認**
   - 空フォルダ = 未実施（評価不可）
   - ファイルあり = 実施済み（評価実施）

5. **評価基準の確認**
   ```bash
   cat C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\prompt.txt
   ```
   prompt.txtから評価項目を抽出

6. **指定AIの評価実施**
   ```bash
   cd C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\evaluations\EVAL_[自分の番号]\
   ```
   各評価項目をチェック

7. **評価レポート作成**
   以下の形式でレポートを作成し、**自分の評価者フォルダ内に保存**：
   ```
   C:\Users\user\Desktop\work\90_cc\20250812\claude-manual-test-100\tests\v0.2\[テスト番号]\evaluations\EVAL_[番号]\evaluation_report_[AI番号].md
   ```

8. **完了報告**
   「[テスト番号] 評価完了（評価者：EVAL_[番号]、対象：[AI番号]、[AI番号]の[何人目]の評価者）」と報告

## 評価レポート形式

```markdown
# [テスト番号] [AI番号] 評価レポート
評価者：EVAL_[自分の番号]
評価日時：[dateコマンドで取得]

## 評価対象
- テスト番号：[テスト番号]
- AI番号：[AI番号]
- 実施状況：実施済み/未実施
- 評価順序：[AI番号]の[何人目]の評価者

## 評価結果
| 項目番号 | 評価項目 | 結果 | 備考 |
|----------|---------|------|------|
| 1 | AI番号フォルダ作成とテンプレートコピー | ○/× | |
| 2 | 作業開始記録 | ○/× | |
| ... | ... | ... | |
| 13 | README2.mdルール遵守 | ○/× | |

## 総合評価
- 達成項目数：X/13
- 達成率：XX%

## 特記事項
- 成功した点
- 失敗した点
- 特殊なエラーパターン
- その他の観察事項
```

## 評価チェック項目（テスト別）

### test1（13項目）
■ 作業完了チェック（10項目）
1. AI番号フォルダ作成とテンプレートコピー完了
2. 作業開始記録の実行
3. folder_Aが存在するか
4. folder_Bが存在するか
5. folder_Cが存在するか
6. folder_A/file_A.txtが存在するか
7. folder_B/file_B.txtが存在するか
8. folder_C/file_C.txtが存在するか
9. file_A.txtに「133」が記載されているか（37+96=133）
10. 作業終了記録の実行

■ work_history.log記録チェック（3項目）
11. 10行の時刻付き記録が存在するか
12. 各記録が指定された項目名で正確に記載されているか
13. README2.mdルール遵守（逐次記録、まとめ記録ではない）

### test2（20項目）
（prompt.txtから抽出して評価）

### test3（30項目）
（prompt.txtから抽出して評価）

### test4（40項目）
（prompt.txtから抽出して評価）

### test5（50項目）
（prompt.txtから抽出して評価）

## 注意事項

- **実施済みAIのみ評価対象**：空フォルダのAIは評価から除外
- **平均達成率は実施済みAIのみで計算**：未実施AIは分母に含めない
- **客観的評価**：YES/NOで明確に判定
- **数値の正確性**：計算結果は完全一致で評価
- **ファイル名**：大文字小文字も含めて完全一致

### 重要：複数評価者による評価について
- **既に評価済みのAIでも、追加の評価者として独立して評価を実施**
- 他の評価者の評価内容は参照しない（独立した視点で評価）
- 自分が何人目の評価者かを把握して記録
- 評価人数に上限はない（4人目、5人目でも評価実施）

### 重要：評価対象の判定基準
- ✅ 評価対象：AIフォルダ内にファイルがある → 実施済み
- ❌ 評価対象外：AIフォルダが空 → 未実施（統計から除外）

---
指示を受けたら上記に従って自律的に評価を開始してください。